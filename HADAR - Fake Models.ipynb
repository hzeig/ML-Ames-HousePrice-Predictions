{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a356198e",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "#### Train, tune, and pickle models using Sweta's cleaned dataset\n",
    "- Sequential Feature Selection\n",
    "- GridSearchCV\n",
    "- Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "491cf9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LinearRegression, HuberRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da0d469",
   "metadata": {},
   "source": [
    "#### Pickle Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d2996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save Model Using Pickle\n",
    "# import pandas\n",
    "# from sklearn import model_selection\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# import pickle\n",
    "# url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "# names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "# dataframe = pandas.read_csv(url, names=names)\n",
    "# array = dataframe.values\n",
    "# X = array[:,0:8]\n",
    "# Y = array[:,8]\n",
    "# test_size = 0.33\n",
    "# seed = 7\n",
    "# X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "# # Fit the model on training set\n",
    "# model = LogisticRegression()\n",
    "# model.fit(X_train, Y_train)\n",
    "# # save the model to disk\n",
    "# filename = 'finalized_model.sav'\n",
    "# pickle.dump(model, open(filename, 'wb'))\n",
    " \n",
    "# # some time later...\n",
    " \n",
    "# # load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# result = loaded_model.score(X_test, Y_test)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd69d259",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6806054",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dummi data/train_final.csv')\n",
    "test = pd.read_csv('dummi data/test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d78e984",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns='SalePrice')\n",
    "y_train = train['SalePrice']\n",
    "X_test = test.drop(columns='SalePrice')\n",
    "y_test = test['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bb3831",
   "metadata": {},
   "source": [
    "### Multivariate Linear Regression Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17bd3568",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# gs = GridSearchCV()\n",
    "\n",
    "# gs_params = {\n",
    "#     ''\n",
    "# }\n",
    "\n",
    "\n",
    "# pipe = make_pipeline(MinMaxScaler(), lm, )\n",
    "\n",
    "pickle.dump(lm, open('fakeLinear.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3610925",
   "metadata": {},
   "source": [
    "### Naive-Bayes Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e688b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb =\n",
    "\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7edd70",
   "metadata": {},
   "source": [
    "### Random Forest Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28acb067",
   "metadata": {},
   "source": [
    "### Gradient Booster Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e6776",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a66d874",
   "metadata": {},
   "source": [
    "### SVM SVC Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7643cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6386ea2",
   "metadata": {},
   "source": [
    "### PCA Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b6f140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8458568b",
   "metadata": {},
   "source": [
    "### Clustering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1793c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
